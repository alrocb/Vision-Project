{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "import tifffile as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALTA PULIR EL BINARIZE Y EL OPEN PARA QUE SEA MAS PRECISO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_contornos(canal,stack_resized):\n",
    "\n",
    "    contornos, _ = cv2.findContours(canal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    regiones_interes = []\n",
    "    for contorno in contornos:\n",
    "        print(\"Contorno detectado\")\n",
    "        x, y, w, h = cv2.boundingRect(contorno)\n",
    "        print(x,y,w,h)\n",
    "\n",
    "        region = stack_resized[y:y+h, x:x+w]\n",
    "        regiones_interes.append(region)\n",
    "    return regiones_interes,contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(imagen_bin,imagen, window_size):\n",
    "    valid_patches = []\n",
    "    for y in range(0, imagen_bin.shape[0] - window_size[0], 7 ):\n",
    "        for x in range(0, imagen_bin.shape[1] - window_size[1], 7 ):\n",
    "  \n",
    "            patch = imagen_bin[y:y+window_size[0], x:x+window_size[1]]\n",
    "\n",
    "            white_pixels = cv2.countNonZero(patch)\n",
    "            black_pixels = patch.size - white_pixels\n",
    "\n",
    "            if white_pixels > 0 and black_pixels > 0:\n",
    "                patch_imagen_original = imagen[y:y+window_size[0], x:x+window_size[1]]\n",
    "                valid_patches.append(patch_imagen_original)\n",
    "    return valid_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(rute):\n",
    "    tif_stack = tf.imread(rute)\n",
    "    print(\"The shape of your image is:\",tif_stack.shape)\n",
    "    print(\"Resizing image...\")\n",
    "    alto,ancho,canales= tif_stack.shape\n",
    "    antiguo_aspect_ratio= ancho/alto\n",
    "    \n",
    "    nuevo_ancho = int(ancho/100)  \n",
    "    nuevo_alto = int(alto/100)  \n",
    "\n",
    "    nuevo_aspect_ratio= nuevo_ancho/ nuevo_alto\n",
    "\n",
    "    # Redimensiona la imagen manteniendo la relación de aspecto\n",
    "    stack_resized = cv2.resize(tif_stack, (nuevo_ancho, nuevo_alto))\n",
    "    \n",
    "    print(\"The new shape is:\",stack_resized.shape)\n",
    "    time.sleep(1)\n",
    "    print(\"Practically we preserve all the aspect ratio when resizing since the original was:\",antiguo_aspect_ratio,\"and the new one is:\", nuevo_aspect_ratio)\n",
    "    time.sleep(1)\n",
    "    print(\"Plotting image...\")\n",
    "    time.sleep(1)\n",
    "    plt.imshow(stack_resized)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Converting image from BGR to HSV...\")\n",
    "    imagen_hsv = cv2.cvtColor(stack_resized, cv2.COLOR_BGR2HSV)\n",
    "    time.sleep(1)\n",
    "    print(\"Extracting Hue channel...\")\n",
    "    canal= imagen_hsv[:,:,:1]\n",
    "    time.sleep(1)\n",
    "    print(\"Canal extracted! Shape:\",canal.shape)\n",
    "    time.sleep(1)\n",
    "    print(\"Visualizing..\")\n",
    "    plt.imshow(canal)\n",
    "    plt.show()\n",
    "    print(\"Preparing to extract contours..\")\n",
    "    regiones_interes,contornos=encontrar_contornos(canal,stack_resized)\n",
    "  \n",
    "    imagen_con_contornos = stack_resized.copy()\n",
    "\n",
    "    print(\"Visualizing extracted contours..\")\n",
    "    # Dibuja los contornos en la imagen\n",
    "    cv2.drawContours(imagen_con_contornos, contornos, -1, (255,0, 0), 9)\n",
    "    plt.imshow(imagen_con_contornos)\n",
    "    plt.axis('off')  \n",
    "    plt.show()\n",
    "\n",
    "    time.sleep(1)\n",
    "    for i in range(len(regiones_interes)):\n",
    "        crop= regiones_interes[i]\n",
    "        time.sleep(1)\n",
    "        print(\"Printing crop number:\",i)\n",
    "        plt.imshow(crop)\n",
    "        plt.axis('off') \n",
    "        plt.show()\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(\"Time to process the cropped images to extract patches..\")\n",
    "\n",
    "    for i in range(len(regiones_interes)):\n",
    "        print(\"Extracting saturation channel from\",i,\"crop...\")\n",
    "        imagen_hsv = cv2.cvtColor(regiones_interes[i], cv2.COLOR_BGR2HSV)\n",
    "        canal_crop= imagen_hsv[:,:,1]\n",
    "        time.sleep(1)\n",
    "        plt.imshow(canal_crop, cmap=\"gray\")\n",
    "        plt.axis('off') \n",
    "        plt.show()\n",
    "\n",
    "        time.sleep(1)\n",
    "        print(\"Binarizing image...\")\n",
    "        umbral, imagen_binaria = cv2.threshold(canal_crop, 35, 180, cv2.THRESH_BINARY)\n",
    "        time.sleep(1)\n",
    "        plt.imshow(imagen_binaria, cmap=\"gray\")\n",
    "        plt.axis('off') \n",
    "        plt.show()\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        print(\"Applying morphological operation to avoid holes and noise... (opening)\")\n",
    "        # Define el kernel para el open\n",
    "        kernel = np.ones((2, 2), np.uint8)  \n",
    "\n",
    "        \n",
    "        imagen_abierta = cv2.morphologyEx(imagen_binaria, cv2.MORPH_OPEN, kernel)\n",
    "        time.sleep(1)\n",
    "\n",
    "        plt.imshow(imagen_abierta, cmap=\"gray\")\n",
    "        plt.axis('off') \n",
    "        plt.show()\n",
    "        time.sleep(1)\n",
    "\n",
    "        print(\"Defining window for sliding window process..\")\n",
    "        window_size=(15,15)\n",
    "        patches=sliding_window(imagen_abierta,regiones_interes[i],window_size)\n",
    "        time.sleep(1)\n",
    "        print(\"Got it! Patches obtained:\",len(patches))\n",
    "        time.sleep(1)\n",
    "\n",
    "        print(\"Visualizing 5 first patches..\")\n",
    "        for i in range (0,5):\n",
    "            plt.imshow(patches[i])\n",
    "            plt.axis('off')  \n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    time.sleep(1)     \n",
    "    print(\"Patches extraction process finished successfully!\")\n",
    "    #return patches\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_file = \"/fhome/mapsiv/QuironHelico/WSI_Example/B22-25-HP.tiff\"\n",
    "extract_patches(tif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_file = \"/fhome/mapsiv/QuironHelico/WSI_Example/B22-35-HP.tiff\"\n",
    "extract_patches(tif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_file = \"/fhome/mapsiv/QuironHelico/WSI_Example/B22-31-HP.tiff\"\n",
    "extract_patches(tif_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alto,ancho,canales= tif_stack.shape\n",
    "alto,ancho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tif_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antiguo_aspect_ratio= ancho/alto\n",
    "\n",
    "nuevo_ancho = int(ancho/100) \n",
    "nuevo_alto = int(alto/100)  \n",
    "\n",
    "nuevo_aspect_ratio= nuevo_ancho/ nuevo_alto\n",
    "\n",
    "\n",
    "stack_resized = cv2.resize(tif_stack, (nuevo_ancho, nuevo_alto))\n",
    "\n",
    "\n",
    "print(\"Prácticamente conservamos todo el aspect ratio redimensionando ya que el antiguo era:\",antiguo_aspect_ratio,\"y el nuevo es:\", nuevo_aspect_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(stack_resized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(stack_resized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagen_hsv = cv2.cvtColor(stack_resized, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "canal= imagen_hsv[:,:,:1]\n",
    "\n",
    "canal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(canal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contornos, _ = cv2.findContours(canal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "regiones_interes = []\n",
    "for contorno in contornos:\n",
    "    print(\"Contorno detectado\")\n",
    "    x, y, w, h = cv2.boundingRect(contorno)\n",
    "    print(x,y,w,h)\n",
    "\n",
    "    region = stack_resized[y:y+h, x:x+w]\n",
    "    regiones_interes.append(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagen_con_contornos = stack_resized.copy()\n",
    "\n",
    "cv2.drawContours(imagen_con_contornos, contornos, -1, (255,0, 0), 9)\n",
    "plt.imshow(imagen_con_contornos)\n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(regiones_interes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop1= regiones_interes[0]\n",
    "crop2= regiones_interes[1]\n",
    "crop3= regiones_interes[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop1)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop2)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop3)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagen_hsv = cv2.cvtColor(crop1, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "canal_crop= imagen_hsv[:,:,1]\n",
    "\n",
    "canal_crop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(canal_crop, cmap=\"gray\")\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "umbral, imagen_binaria = cv2.threshold(canal_crop, 10, 180, cv2.THRESH_BINARY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagen_binaria, cmap=\"gray\")\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = np.ones((2, 2), np.uint8)  \n",
    "\n",
    "\n",
    "imagen_abierta = cv2.morphologyEx(imagen_binaria, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "plt.imshow(imagen_abierta, cmap=\"gray\")\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contornos, _ = cv2.findContours(imagen_abierta, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "regiones_interes = []\n",
    "for contorno in contornos:\n",
    "    print(\"Contorno detectado\")\n",
    "    x, y, w, h = cv2.boundingRect(contorno)\n",
    "    print(x,y,w,h)\n",
    "\n",
    "    region = stack_resized[y:y+h, x:x+w]\n",
    "    regiones_interes.append(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagen_con_contornos = crop1.copy()\n",
    "\n",
    "cv2.drawContours(imagen_con_contornos, contornos, -1, (255,0, 0), 1)\n",
    "plt.imshow(imagen_con_contornos)\n",
    "plt.axis('off')  # Desactiva los ejes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(imagen_bin,imagen, window_size):\n",
    "    valid_patches = []\n",
    "    for y in range(0, imagen_bin.shape[0] - window_size[0] + 10):\n",
    "        for x in range(0, imagen_bin.shape[1] - window_size[1] + 10):\n",
    "            # Extrae el patch actual\n",
    "            patch = imagen_bin[y:y+window_size[0], x:x+window_size[1]]\n",
    "\n",
    "            # Calcula la proporción de píxeles blancos en el patch\n",
    "            white_pixels = np.sum(patch == 255)  # Suponiendo que el blanco es 255 en una imagen binarizada\n",
    "\n",
    "            # Calcula la proporción de píxeles negros en el patch\n",
    "            black_pixels = np.sum(patch == 0)  # Suponiendo que el negro es 0 en una imagen binarizada\n",
    "            # Verifica si el patch contiene tanto blanco como negro\n",
    "            if white_pixels > 0:\n",
    "                patch_imagen_original = imagen[y:y+window_size[0], x:x+window_size[1]]\n",
    "                valid_patches.append(patch_imagen_original)\n",
    "            \n",
    "    return valid_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(imagen_bin,imagen, window_size):\n",
    "    valid_patches = []\n",
    "    for y in range(0, imagen_bin.shape[0] - window_size[0], 7 ):\n",
    "        for x in range(0, imagen_bin.shape[1] - window_size[1], 7 ):\n",
    "            # Extrae el patch actual\n",
    "            patch = imagen_bin[y:y+window_size[0], x:x+window_size[1]]\n",
    "\n",
    "            white_pixels = cv2.countNonZero(patch)\n",
    "            black_pixels = patch.size - white_pixels\n",
    "\n",
    "            if white_pixels > 0 and black_pixels > 0:\n",
    "                patch_imagen_original = imagen[y:y+window_size[0], x:x+window_size[1]]\n",
    "                valid_patches.append(patch_imagen_original)\n",
    "    return valid_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size=(15,15)\n",
    "patches=sliding_window(imagen_abierta,crop1,window_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,50):\n",
    "    plt.imshow(patches[i])\n",
    "    plt.axis('off')  # Desactiva los ejes\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
